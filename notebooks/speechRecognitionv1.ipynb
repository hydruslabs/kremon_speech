{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMbeU7XUIA53",
    "outputId": "b0599a48-0607-4645-8a93-527f4f696623",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechRecognitionv1.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi6JfrvU3_R5"
   },
   "source": [
    "# Nmedia/ction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-FFpKy1MwDw"
   },
   "source": [
    "Installation of Pydub for Audio File Manipulation and Analysis of audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWMJRzpHKedM",
    "outputId": "e418106a-7c1e-4b70-a749-328a1a8fba28",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydub in /home/paperspace/.local/lib/python3.9/site-packages (0.25.1)\n",
      "Requirement already satisfied: torchaudio in /home/paperspace/.local/lib/python3.9/site-packages (0.12.1+cu116)\n",
      "Requirement already satisfied: torch in /home/paperspace/.local/lib/python3.9/site-packages (1.12.1+cu116)\n",
      "Requirement already satisfied: comet-ml in /home/paperspace/.local/lib/python3.9/site-packages (3.33.3)\n",
      "Requirement already satisfied: typing-extensions in /home/paperspace/.local/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (4.17.3)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (0.10.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (2.28.2)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (1.13.0)\n",
      "Requirement already satisfied: simplejson in /usr/lib/python3/dist-packages (from comet-ml) (3.16.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from comet-ml) (1.14.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (1.26.14)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (0.57.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (1.14.1)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (3.0.3)\n",
      "Requirement already satisfied: everett[ini]<3.2.0,>=1.0.1 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (3.1.0)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (0.21.5)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (13.4.1)\n",
      "Requirement already satisfied: configobj in /usr/lib/python3/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.6)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/paperspace/.local/lib/python3.9/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (18.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/lib/python3/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.15.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/paperspace/.local/lib/python3.9/site-packages (from requests>=2.18.4->comet-ml) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet-ml) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet-ml) (2019.11.28)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/paperspace/.local/lib/python3.9/site-packages (from rich>=13.3.2->comet-ml) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/paperspace/.local/lib/python3.9/site-packages (from rich>=13.3.2->comet-ml) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/paperspace/.local/lib/python3.9/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchaudio in /home/paperspace/.local/lib/python3.9/site-packages (0.12.1+cu116)\n",
      "Requirement already satisfied: torch in /home/paperspace/.local/lib/python3.9/site-packages (1.12.1+cu116)\n",
      "Requirement already satisfied: comet-ml in /home/paperspace/.local/lib/python3.9/site-packages (3.33.3)\n",
      "Requirement already satisfied: typing-extensions in /home/paperspace/.local/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (4.17.3)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (0.10.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (2.28.2)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (1.13.0)\n",
      "Requirement already satisfied: simplejson in /usr/lib/python3/dist-packages (from comet-ml) (3.16.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from comet-ml) (1.14.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (1.26.14)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (0.57.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (1.14.1)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (3.0.3)\n",
      "Requirement already satisfied: everett[ini]<3.2.0,>=1.0.1 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (3.1.0)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (0.21.5)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/paperspace/.local/lib/python3.9/site-packages (from comet-ml) (13.4.1)\n",
      "Requirement already satisfied: configobj in /usr/lib/python3/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.6)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/paperspace/.local/lib/python3.9/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (18.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/lib/python3/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.15.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/paperspace/.local/lib/python3.9/site-packages (from requests>=2.18.4->comet-ml) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet-ml) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet-ml) (2019.11.28)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/paperspace/.local/lib/python3.9/site-packages (from rich>=13.3.2->comet-ml) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/paperspace/.local/lib/python3.9/site-packages (from rich>=13.3.2->comet-ml) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/paperspace/.local/lib/python3.9/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub torchaudio torch comet-ml\n",
    "!pip install torchaudio torch comet-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BMPi6PbuJK-j",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment, effects\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9GbjrLp3NgFy"
   },
   "outputs": [],
   "source": [
    "def _levenshtein_distance(ref, hyp):\n",
    "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
    "    between two sequences. Informally, the levenshtein disctance is defined as\n",
    "    the minimum number of single-character edits (substitutions, insertions or\n",
    "    deletions) required to change one word into the other. We can naturally\n",
    "    extend the edits to word level when calculate levenshtein disctance for\n",
    "    two sentences.\n",
    "    \"\"\"\n",
    "    m = len(ref)\n",
    "    n = len(hyp)\n",
    "\n",
    "    # special case\n",
    "    if ref == hyp:\n",
    "        return 0\n",
    "    if m == 0:\n",
    "        return n\n",
    "    if n == 0:\n",
    "        return m\n",
    "\n",
    "    if m < n:\n",
    "        ref, hyp = hyp, ref\n",
    "        m, n = n, m\n",
    "\n",
    "    # use O(min(m, n)) space\n",
    "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
    "\n",
    "    # initialize distance matrix\n",
    "    for j in range(0,n + 1):\n",
    "        distance[0][j] = j\n",
    "\n",
    "    # calculate levenshtein distance\n",
    "    for i in range(1, m + 1):\n",
    "        prev_row_idx = (i - 1) % 2\n",
    "        cur_row_idx = i % 2\n",
    "        distance[cur_row_idx][0] = i\n",
    "        for j in range(1, n + 1):\n",
    "            if ref[i - 1] == hyp[j - 1]:\n",
    "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
    "            else:\n",
    "                s_num = distance[prev_row_idx][j - 1] + 1\n",
    "                i_num = distance[cur_row_idx][j - 1] + 1\n",
    "                d_num = distance[prev_row_idx][j] + 1\n",
    "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
    "\n",
    "    return distance[m % 2][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6Xya-UoaNk5W"
   },
   "outputs": [],
   "source": [
    "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
    "    hypothesis sequence in word-level.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param delimiter: Delimiter of input sentences.\n",
    "    :type delimiter: char\n",
    "    :return: Levenshtein distance and word number of reference sentence.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    ref_words = reference.split(delimiter)\n",
    "    hyp_words = hypothesis.split(delimiter)\n",
    "\n",
    "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
    "    return float(edit_distance), len(ref_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XsaZXrXLNoNr"
   },
   "outputs": [],
   "source": [
    "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
    "    hypothesis sequence in char-level.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param remove_space: Whether remove internal space characters\n",
    "    :type remove_space: bool\n",
    "    :return: Levenshtein distance and length of reference sentence.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    join_char = ' '\n",
    "    if remove_space == True:\n",
    "        join_char = ''\n",
    "\n",
    "    reference = join_char.join(filter(None, reference.split(' ')))\n",
    "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
    "\n",
    "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
    "    return float(edit_distance), len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-v6cfNBZNuv3"
   },
   "outputs": [],
   "source": [
    "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
    "    hypothesis text in word-level. WER is defined as:\n",
    "    .. math::\n",
    "        WER = (Sw + Dw + Iw) / Nw\n",
    "    where\n",
    "    .. code-block:: text\n",
    "        Sw is the number of words subsituted,\n",
    "        Dw is the number of words deleted,\n",
    "        Iw is the number of words inserted,\n",
    "        Nw is the number of words in the reference\n",
    "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
    "    that empty items will be removed when splitting sentences by delimiter.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param delimiter: Delimiter of input sentences.\n",
    "    :type delimiter: char\n",
    "    :return: Word error rate.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If word number of reference is zero.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
    "                                         delimiter)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
    "\n",
    "    wer = float(edit_distance) / ref_len\n",
    "    return wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mv-fUTHpN0wx"
   },
   "outputs": [],
   "source": [
    "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
    "    hypothesis text in char-level. CER is defined as:\n",
    "    .. math::\n",
    "        CER = (Sc + Dc + Ic) / Nc\n",
    "    where\n",
    "    .. code-block:: text\n",
    "        Sc is the number of characters substituted,\n",
    "        Dc is the number of characters deleted,\n",
    "        Ic is the number of characters inserted\n",
    "        Nc is the number of characters in the reference\n",
    "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
    "    encoded to unicode. Please draw an attention that the leading and tailing\n",
    "    space characters will be truncated and multiple consecutive space\n",
    "    characters in a sentence will be replaced by one space character.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param remove_space: Whether remove internal space characters\n",
    "    :type remove_space: bool\n",
    "    :return: Character error rate.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If the reference length is zero.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
    "                                         remove_space)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
    "\n",
    "    cer = float(edit_distance) / ref_len\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ER6KThZzN9-o"
   },
   "outputs": [],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        < 1\n",
    "        . 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text.replace(\"\\n\", \"\"):\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PezH0w3EOB0r",
    "outputId": "359bcc88-b4cb-4003-8b22-8cfa9f2152f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/.local/lib/python3.9/site-packages/torchaudio/functional/functional.py:539: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9uXaJ6AoOODZ"
   },
   "outputs": [],
   "source": [
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LDsA9e68ORG6"
   },
   "outputs": [],
   "source": [
    "text_transform = TextTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uNghx3G_OVi9"
   },
   "outputs": [],
   "source": [
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'valid':\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2dS5tX66q5RO"
   },
   "outputs": [],
   "source": [
    "def data_processing_2(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, utterance) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(torch.from_numpy(waveform).float()).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'valid':\n",
    "            spec = valid_audio_transforms(torch.from_numpy(waveform).float()).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "21d_YwyZOXRZ"
   },
   "outputs": [],
   "source": [
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "\targ_maxes = torch.argmax(output, dim=2)\n",
    "\tdecodes = []\n",
    "\ttargets = []\n",
    "\tfor i, args in enumerate(arg_maxes):\n",
    "\t\tdecode = []\n",
    "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "\t\tfor j, index in enumerate(args):\n",
    "\t\t\tif index != blank_label:\n",
    "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tdecode.append(index.item())\n",
    "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
    "\treturn decodes, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWVjCreOOqdD"
   },
   "source": [
    "# The Model\n",
    "Bases on Deep Speech 2 with some modifications\n",
    "\n",
    "**CNN Layer Norm**\n",
    "\n",
    "**Residual CNN**\n",
    "\n",
    "**Bidirectioal GRU**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oRUe-jelPRJx"
   },
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "00deFiPIPWzx"
   },
   "outputs": [],
   "source": [
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7Q0UNNl4PbQx"
   },
   "outputs": [],
   "source": [
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "P5foI-4aPe62"
   },
   "outputs": [],
   "source": [
    "class SpeechRecognitionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HLembjyqS4Wa"
   },
   "outputs": [],
   "source": [
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jEUe8YK9TBT0"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            iter_meter.step()\n",
    "            train_loss += loss.item()/ len(train_loader)\n",
    "            \n",
    "            \n",
    "\n",
    "           # if batch_idx % 1 == 0 or data_len == ((batch_idx + 1) * 5) :\n",
    "            #    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "             #       epoch, (batch_idx + 1) * len(spectrograms), data_len,\n",
    "              #      100. * batch_idx / len(train_loader), loss.item()))\n",
    "                \n",
    "    print('Train Epoch: {}: Average loss: {:.4f}'.format(epoch,train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hEx7b6lyTDy3"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion, epoch, iter_meter):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "            for i, _data in enumerate(test_loader):\n",
    "                spectrograms, labels, input_lengths, label_lengths = _data \n",
    "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "                output = model(spectrograms)  # (batch, time, n_class)\n",
    "                output = F.log_softmax(output, dim=2)\n",
    "                output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "                loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "                test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "                decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "                for j in range(len(decoded_preds)):\n",
    "                    test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                    test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "\n",
    "    avg_cer = sum(test_cer)/len(test_cer)\n",
    "    avg_wer = sum(test_wer)/len(test_wer)\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}'.format(test_loss, avg_cer, avg_wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ak5mmtGyNeXi"
   },
   "outputs": [],
   "source": [
    "def avg_wer(wer_scores, combined_ref_len):\n",
    "    return float(sum(wer_scores)) / float(combined_ref_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechRecognitionv1.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m'Batch 1 May Kelly 0.pickle'\u001b[0m*  \u001b[01;32m'Batch 1 May Kelly 7.pickle'\u001b[0m*\n",
      "\u001b[01;32m'Batch 1 May Kelly 1.pickle'\u001b[0m*  \u001b[01;32m'Batch 1 May Kelly 8.pickle'\u001b[0m*\n",
      "\u001b[01;32m'Batch 1 May Kelly 2.pickle'\u001b[0m*  \u001b[01;32m'Batch 1 May Kelly 9.pickle'\u001b[0m*\n",
      "\u001b[01;32m'Batch 1 May Kelly 3.pickle'\u001b[0m*  \u001b[01;32m'Batch 2 May Kelly 0.pickle'\u001b[0m*\n",
      "\u001b[01;32m'Batch 1 May Kelly 4.pickle'\u001b[0m*  \u001b[01;32m'Batch 2 May Kelly 1.pickle'\u001b[0m*\n",
      "\u001b[01;32m'Batch 1 May Kelly 5.pickle'\u001b[0m*  \u001b[01;32m'Batch 2 May Kelly 2.pickle'\u001b[0m*\n",
      "\u001b[01;32m'Batch 1 May Kelly 6.pickle'\u001b[0m*  \u001b[01;32m'Batch 2 May Kelly 3.pickle'\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls /media/kremon-storage/dataset-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEJVlaDn6nVY",
    "outputId": "8815fa29-daa8-4687-e87e-ec6136082517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with: Batch 1 May Kelly 0.pickle\n",
      "Working with: Batch 1 May Kelly 1.pickle\n",
      "Working with: Batch 1 May Kelly 2.pickle\n",
      "Working with: Batch 1 May Kelly 3.pickle\n",
      "Working with: Batch 1 May Kelly 4.pickle\n",
      "Working with: Batch 1 May Kelly 5.pickle\n",
      "Working with: Batch 1 May Kelly 6.pickle\n",
      "Working with: Batch 1 May Kelly 7.pickle\n",
      "Working with: Batch 1 May Kelly 8.pickle\n",
      "Working with: Batch 1 May Kelly 9.pickle\n",
      "Working with: Batch 2 May Kelly 0.pickle\n",
      "Working with: Batch 2 May Kelly 1.pickle\n",
      "Working with: Batch 2 May Kelly 2.pickle\n",
      "Working with: Batch 2 May Kelly 3.pickle\n"
     ]
    }
   ],
   "source": [
    "#pickle_list = ['data_16kHz.pickle','Batch 1 2021 David Segmented pt1.pickle','Batch 1 2021 David Segmented pt3.pickle','Batch 1 2021 David Segmented pt4.pickle','Batch 1 2021 David Segmented pt5.pickle','Batch 1 2021 David Segmented pt7.pickle']\n",
    "pickle_list = [\n",
    "    'Batch 1 May Kelly 0.pickle',\n",
    "    'Batch 1 May Kelly 1.pickle',\n",
    "    'Batch 1 May Kelly 2.pickle',\n",
    "    'Batch 1 May Kelly 3.pickle',\n",
    "    'Batch 1 May Kelly 4.pickle',\n",
    "    'Batch 1 May Kelly 5.pickle',\n",
    "    'Batch 1 May Kelly 6.pickle',\n",
    "    'Batch 1 May Kelly 7.pickle',\n",
    "    'Batch 1 May Kelly 8.pickle',\n",
    "    'Batch 1 May Kelly 9.pickle',\n",
    "    'Batch 2 May Kelly 0.pickle',\n",
    "    'Batch 2 May Kelly 1.pickle',\n",
    "    'Batch 2 May Kelly 2.pickle',\n",
    "    'Batch 2 May Kelly 3.pickle'\n",
    "]\n",
    "b = []\n",
    "for filename in pickle_list:\n",
    "    print(\"Working with: \"+filename)\n",
    "    with open('/media/kremon-storage/dataset-01/'+filename, 'rb') as handle:\n",
    "        b = b + pickle.load(handle)\n",
    "        \n",
    "random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = b[0:2000]\n",
    "test_set = b[2000:2300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "hparams = {\n",
    "        \"n_cnn_layers\": 3,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 29,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\":2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"batch_size\": 30,\n",
    "        \"epochs\": 50\n",
    "    }\n",
    "\n",
    "\n",
    "train_2_loader = data.DataLoader(dataset=train_set,\n",
    "                                batch_size=hparams[\"batch_size\"],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing_2(x, 'train'),\n",
    "                                **kwargs)\n",
    "\n",
    "\n",
    "test_2_loader = data.DataLoader(dataset=test_set,\n",
    "                                batch_size=5,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing_2(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = SpeechRecognitionModel(\n",
    "            hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "            hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "            ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechRecognitionModel(\n",
      "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (rescnn_layers): Sequential(\n",
      "    (0): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (birnn_layers): Sequential(\n",
      "    (0): BidirectionalGRU(\n",
      "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): GELU(approximate=none)\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "mOu7myfFcoie",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1: Average loss: 5.0366\n",
      "Test set: Average loss: 3.0065, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 2: Average loss: 2.9087\n",
      "Test set: Average loss: 2.9354, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 3: Average loss: 2.8693\n",
      "Test set: Average loss: 2.9079, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 4: Average loss: 2.8547\n",
      "Test set: Average loss: 2.8949, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 5: Average loss: 2.8511\n",
      "Test set: Average loss: 2.9057, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 6: Average loss: 2.8625\n",
      "Test set: Average loss: 2.9126, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 7: Average loss: 2.8397\n",
      "Test set: Average loss: 2.8940, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 8: Average loss: 2.8480\n",
      "Test set: Average loss: 3.2299, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 9: Average loss: 3.0719\n",
      "Test set: Average loss: 2.9485, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 10: Average loss: 2.9097\n",
      "Test set: Average loss: 2.9806, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 11: Average loss: 2.9361\n",
      "Test set: Average loss: 2.9431, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 12: Average loss: 2.8574\n",
      "Test set: Average loss: 2.9293, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 13: Average loss: 2.8673\n",
      "Test set: Average loss: 2.9100, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 14: Average loss: 2.8507\n",
      "Test set: Average loss: 2.9273, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 15: Average loss: 2.9113\n",
      "Test set: Average loss: 3.0864, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 16: Average loss: 2.9596\n",
      "Test set: Average loss: 3.4351, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 17: Average loss: 2.9501\n",
      "Test set: Average loss: 2.9026, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 18: Average loss: 2.8494\n",
      "Test set: Average loss: 2.8962, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 19: Average loss: 2.8370\n",
      "Test set: Average loss: 2.9075, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 20: Average loss: 2.8453\n",
      "Test set: Average loss: 2.9438, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 21: Average loss: 2.8652\n",
      "Test set: Average loss: 2.8958, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 22: Average loss: 2.8421\n",
      "Test set: Average loss: 2.9036, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 23: Average loss: 2.8453\n",
      "Test set: Average loss: 2.9641, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 24: Average loss: 2.8589\n",
      "Test set: Average loss: 2.9596, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 25: Average loss: 2.8878\n",
      "Test set: Average loss: 2.8929, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 26: Average loss: 2.8817\n",
      "Test set: Average loss: 2.8921, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 27: Average loss: 2.8796\n",
      "Test set: Average loss: 2.9210, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 28: Average loss: 2.8424\n",
      "Test set: Average loss: 2.8957, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 29: Average loss: 2.8407\n",
      "Test set: Average loss: 2.8944, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 30: Average loss: 2.8372\n",
      "Test set: Average loss: 2.9291, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 31: Average loss: 2.8406\n",
      "Test set: Average loss: 2.9045, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 32: Average loss: 2.8350\n",
      "Test set: Average loss: 2.9016, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 33: Average loss: 2.8341\n",
      "Test set: Average loss: 2.9015, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 34: Average loss: 2.8459\n",
      "Test set: Average loss: 2.8917, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 35: Average loss: 2.8385\n",
      "Test set: Average loss: 2.9126, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 36: Average loss: 2.8382\n",
      "Test set: Average loss: 2.8938, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 37: Average loss: 2.8342\n",
      "Test set: Average loss: 2.8905, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 38: Average loss: 2.8451\n",
      "Test set: Average loss: 2.8970, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 39: Average loss: 2.8576\n",
      "Test set: Average loss: 2.8906, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 40: Average loss: 2.8519\n",
      "Test set: Average loss: 2.9268, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 41: Average loss: 2.8483\n",
      "Test set: Average loss: 2.9295, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 42: Average loss: 2.8420\n",
      "Test set: Average loss: 2.8967, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 43: Average loss: 2.8321\n",
      "Test set: Average loss: 2.8993, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 44: Average loss: 2.8357\n",
      "Test set: Average loss: 2.8974, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 45: Average loss: 2.8353\n",
      "Test set: Average loss: 2.9010, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 46: Average loss: 2.8314\n",
      "Test set: Average loss: 2.8943, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 47: Average loss: 2.8329\n",
      "Test set: Average loss: 2.8885, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 48: Average loss: 2.8304\n",
      "Test set: Average loss: 2.8956, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 49: Average loss: 2.8299\n",
      "Test set: Average loss: 2.8901, Average CER: 1.000000 Average WER: 0.9906\n",
      "Train Epoch: 50: Average loss: 2.8324\n",
      "Test set: Average loss: 2.8894, Average CER: 1.000000 Average WER: 0.9906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "          \n",
    "#Test different optimizers \n",
    "#optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "#optimizer = optim.SGD(model.parameters(), lr = hparams['learning_rate'], momentum = 0.3)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['learning_rate'])\n",
    "    \n",
    "\n",
    "criterion = nn.CTCLoss(blank=28).to(device)\n",
    "\n",
    "\n",
    "# Look into this learning rate scheduler seems odd?!\n",
    "# anneal strategy????\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                                steps_per_epoch=int(len(train_2_loader)),\n",
    "                                                epochs=hparams['epochs'],\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "epochs = hparams['epochs']\n",
    "iter_meter = IterMeter()\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_2_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n",
    "        test(model, device, test_2_loader, criterion, epoch, iter_meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SpeechRecognitionModel' object has no attribute 'clear_param_store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear_param_store\u001b[49m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SpeechRecognitionModel' object has no attribute 'clear_param_store'"
     ]
    }
   ],
   "source": [
    "model.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=fb45c1d7e2db089f0410647524710807d225663a3750992df1e8e29b119abb4c\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/a7/0c/d53673ba405bcb572989c614f77c87833b03c3ca07d1f3e48e\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.57.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Downloading llvmlite-0.40.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.25,>=1.21 in /usr/local/lib/python3.9/dist-packages (from numba) (1.23.4)\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.40.0 numba-0.57.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = cuda.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numba.cuda.cudadrv.devices._DeviceList at 0x7f07878b8df0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2881"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = cuda.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_2_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11436754432\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 29 10:29:42 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 41%   48C    P8    16W / 140W |  15703MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_stats():\n",
    "    print(torch.cuda.memory_allocated()/1024**2)\n",
    "    print(torch.cuda.memory_cached()/1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.57.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Downloading llvmlite-0.40.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.25,>=1.21 in /usr/local/lib/python3.9/dist-packages (from numba) (1.23.4)\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.40.0 numba-0.57.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7f0025f20a40 to Device at 0x7f002c0c59a0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvtop: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvtop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.60693359375\n",
      "14136.0\n"
     ]
    }
   ],
   "source": [
    "memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred during reset of GPU 00000000:00:05.0: Unknown Error\n",
      "\n",
      "1 device did not complete reset successfully, and may be in an unstable state. Please reboot your system.\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi --gpu-reset -i 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py:121\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 121\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred during reset of GPU 00000000:00:05.0: Unknown Error\n",
      "\n",
      "1 device did not complete reset successfully, and may be in an unstable state. Please reboot your system.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'empty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'empty'"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
