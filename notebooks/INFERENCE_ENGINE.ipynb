{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8284c039-81fe-4f7a-97f6-850e7e8a51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.performanceMetrics import cer\n",
    "from utils.performanceMetrics import wer\n",
    "from utils.misc import IterMeter\n",
    "from utils.misc import GreedyDecoder\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment, effects\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import utils.transformations.textTransform as text_trans #????? \n",
    "\n",
    "import utils.networkConfigurations.SpeechRecognitionModel_0_0 as network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee83447-76b6-4166-9b0e-901c16dded4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/.local/lib/python3.9/site-packages/torchaudio/functional/functional.py:539: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "text_transform = text_trans.TextTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc29c4f-6c82-4f83-b2fe-ac46fd090a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, utterance) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(torch.from_numpy(waveform).float()).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'valid':\n",
    "            spec = valid_audio_transforms(torch.from_numpy(waveform).float()).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5352d126-6367-490f-9b49-40fab71bec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_wer(wer_scores, combined_ref_len):\n",
    "    return float(sum(wer_scores)) / float(combined_ref_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5460c384-ac27-46b2-80a9-26f5388f3687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechRecognitionModel(\n",
      "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (rescnn_layers): Sequential(\n",
      "    (0): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (birnn_layers): Sequential(\n",
      "    (0): BidirectionalGRU(\n",
      "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): GELU(approximate=none)\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
      "  )\n",
      ")\n",
      "{'n_cnn_layers': 3, 'n_rnn_layers': 5, 'rnn_dim': 512, 'n_class': 29, 'n_feats': 128, 'stride': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 30, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "hparams = {\n",
    "        \"n_cnn_layers\": 3,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 29,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\":2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 30,\n",
    "        \"epochs\": 100\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = network.SpeechRecognitionModel(\n",
    "            hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "            hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "            ).to(device)\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['learning_rate'])\n",
    "    \n",
    "\n",
    "criterion = nn.CTCLoss(blank=28).to(device)\n",
    "\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                                steps_per_epoch=2000,\n",
    "                                                epochs=hparams['epochs'],\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "epochs = hparams['epochs']\n",
    "iter_meter = IterMeter()\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eee9f44-6f62-464e-9e27-382470625fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "Loading data from:../data/final/data_clean_batch_1.pickle\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "database_location = '../data/final/data_clean_batch_1.pickle'\n",
    "\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print('Loading data from:'+database_location)\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "with open(database_location, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "\n",
    "\n",
    "train_set = b[0:2000]\n",
    "test_set = b[2000:2300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af663e8c-45ae-4578-904f-df55630a8749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "277d5da2-8c8e-408d-82d7-0648a262491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00276384, -0.00298204, -0.00305477, ..., -0.0004364 ,\n",
       "         -0.00138192, -0.00065459]]),\n",
       " 'ME KINN ARIVE')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2000+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a71571a5-0378-4a53-956c-f33d2bf384e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"../models/\"+\"model_20_06_2023_10_30_52_100.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b33a6fb5-48a0-434a-a70c-7f728ef8f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['me ki arive']\n",
      "['me kinn arive']\n",
      "1\n",
      "[' bann a dolesan ex ekxppri zot zot zot mem par sa tip dey de viio lan s la']\n",
      "['bann adolesan exprim exprim zot zot zot mem par sa tip violans la']\n",
      "2\n",
      "['kir i perdir par skann']\n",
      "['ki ou pe rod dir par sote']\n",
      "3\n",
      "['omo pa mo pak kone tro kii imi kin li ki tpe ro dir mee boukou do fero stonnh zordi dan moris ki la poliszz zeskameler me pi demidiet ti ena bann kas la bro dan la renioni ti pe role ek don']\n",
      "['bon mo pa mo pa kone tro ki ki manier li ki li ti pe rod dir me boukou de personn setonne zordi dan moris ki lapolis ziska ler depi ti ena bann case ladrog dan la renion ki ti pe roule ek donk']\n",
      "4\n",
      "['be dot pou bazin kapataa axsie']\n",
      "['be zot pou bizin kapav travay lor la']\n",
      "5\n",
      "['bon swar']\n",
      "['bon swar']\n",
      "6\n",
      "['ki enn zen donn lesa lnna t li pe devlopl pe degouver kouma fer sa']\n",
      "['ki enn zen a adolesan ena ki li pe devlope pe dekouver kouma fer sa']\n",
      "7\n",
      "['no malerral man se komn sa ']\n",
      "['ek malerezman li koumsa']\n",
      "8\n",
      "[' soubash gobin  ki konsultan ki enn zournalis de karyer epoi telefor n finn gag losile lezispekt lexper an konskiti ean dan sikenm tou sa bann zafer la dimann enn ranfoselman ']\n",
      "['soubash gobin ki konsiltan ek ki enn zournalis de karier apre o telefonn nou finn gagn osi le lezis ek lexper en konstitision parski li kan mem tou sa bann zafer la diman enn renforsman']\n",
      "9\n",
      "['eski ouu ena lemm bronsantif']\n",
      "['eski ou ena le mem resanti']\n",
      "10\n",
      "['konpeksin dora']\n",
      "['konpetision european']\n",
      "11\n",
      "['eseplik etait']\n",
      "['explike tarik']\n",
      "12\n",
      "['nle ma ke ennpaz epeb']\n",
      "['nou mank enn paz de pub']\n",
      "-------------------------------------------------------------------------------------\n",
      "0\n",
      "['donk bann problem koumans leve apartir la']\n",
      "['donk bann problem koumans leve apartir la']\n",
      "1\n",
      "['o pli o nivod du pe bi tou s monseigneur piat inn dir sa se enn verite malerezman ek ti bizin bann dimounn kouma li avekk sifizaman kouraz ki vini ki pou dir']\n",
      "['o pli o nivo du pei bin tou sa monseigneur piat inn dir sa se enn verite malerezman ek ti bizin bann dimounn kouma li avek sifizaman kouraz ki vini ki pou dir']\n",
      "2\n",
      "['me ena boukou soz ki mo panse the policies ha to changeiei']\n",
      "['me ena boukou soz ki mo panse the policies had to change']\n",
      "3\n",
      "['kan ou get bien listwar de lile moris depi avan lindepandans oumem apre lindepandans konpran ban evenman de la grev d ek tou vini mem finn ena boukou']\n",
      "['kan ou get bien listwar de lile moris depi avan lindepandans ou mem apre lindepandans konpran bann evennman de la grev de ek tou vini mem finn ena boukou']\n",
      "4\n",
      "['apre la mor de vaghjeee der ramesh jewowolall vinnn']\n",
      "['apre la mor de vaghjee ler ramesh jewoolall vinn']\n",
      "5\n",
      "['kifer ou dir s']\n",
      "['kifer ou dir sa']\n",
      "6\n",
      "['sa siranser de konsomasion ki aport boukou larzan me ki pena lavenir san konte le problem ekologik']\n",
      "['sa siranser de konsomasion ki aport boukou larzan me ki pena lavenir san konte le problem ekologik']\n",
      "7\n",
      "['ou fer ou ladverser demare apre fin amon']\n",
      "['ou fer ou ladverser demare apre finalman']\n",
      "8\n",
      "['eski laz pran an konsiderasion dan le swa enn levek']\n",
      "['eski laz pran an konsiderasion dan le swa enn levek']\n",
      "9\n",
      "['vreman difisil ou entan ki rekter ki lektir ou ena lor la']\n",
      "['vreman difisil ou en tan ki rekter ki lektir ou ena lor la']\n",
      "10\n",
      "['mersi oumem']\n",
      "['mersi oumem']\n",
      "11\n",
      "['kris valaydon mersi boukou']\n",
      "['kris valaydon mersi boukou ']\n",
      "12\n",
      "['pou sa bann aksion la']\n",
      "['pou sa bann aksion la']\n"
     ]
    }
   ],
   "source": [
    "test_1 = []\n",
    "test_1.append(b[2000+3])\n",
    "test_1.append(b[2000+14])\n",
    "test_1.append(b[2000+45])\n",
    "test_1.append(b[2000+58])\n",
    "test_1.append(b[2000+73])\n",
    "test_1.append(b[2000+83])\n",
    "test_1.append(b[2000+98])\n",
    "test_1.append(b[2000+117])\n",
    "test_1.append(b[2000+173])\n",
    "test_1.append(b[2000+209])\n",
    "test_1.append(b[2000+241])\n",
    "test_1.append(b[2000+285])\n",
    "test_1.append(b[2000+297])\n",
    "\n",
    "valid_loader = data.DataLoader(dataset=test_1,\n",
    "                                batch_size=1,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "for i, _data in enumerate(valid_loader):\n",
    "    print(i)\n",
    "    spectrograms, labels, input_lengths, label_lengths = _data\n",
    "    spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "    output = model(spectrograms)  # (batch, time, n_class)\n",
    "    output = F.log_softmax(output, dim=2)\n",
    "    output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "    decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "    print(decoded_preds)\n",
    "    print(decoded_targets)\n",
    "    \n",
    "print(\"-------------------------------------------------------------------------------------\")    \n",
    "    \n",
    "train_1 = []\n",
    "train_1.append(b[19])\n",
    "train_1.append(b[24])\n",
    "train_1.append(b[25])\n",
    "train_1.append(b[26])\n",
    "train_1.append(b[30])\n",
    "train_1.append(b[41])\n",
    "train_1.append(b[50])\n",
    "train_1.append(b[54])\n",
    "train_1.append(b[63])\n",
    "train_1.append(b[66])\n",
    "train_1.append(b[72])\n",
    "train_1.append(b[80])\n",
    "train_1.append(b[92])\n",
    "\n",
    "\n",
    "valid_loader = data.DataLoader(dataset=train_1,\n",
    "                                batch_size=1,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "for i, _data in enumerate(valid_loader):\n",
    "    print(i)\n",
    "    spectrograms, labels, input_lengths, label_lengths = _data\n",
    "    spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "    output = model(spectrograms)  # (batch, time, n_class)\n",
    "    output = F.log_softmax(output, dim=2)\n",
    "    output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "    decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "    print(decoded_preds)\n",
    "    print(decoded_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7c959-a5f7-4093-8e78-d2b34cab70db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7fb71f-688f-40d8-9ecb-0b386fd96f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepocessed_data=b[2000:2300]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
